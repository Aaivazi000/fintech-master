{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fundamentals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all columns that have \"Current\" in them, we will not be using those for our NN\n",
    "cols = [c for c in df.columns if 'Current' not in c]\n",
    "df2 = df[cols].drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop missing data\n",
    "df2 = df2.dropna()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SP500 w/ sectors\n",
    "df3 = pd.read_csv('SP500_sectors_filled2.csv', index_col = 'date', parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swap date and Name for index\n",
    "df3['date'] = df3.index\n",
    "df3.index = df3['Name']\n",
    "df3 = df3.drop(['Name'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get same company names\n",
    "sp500_names = df3.index.unique()\n",
    "fundamental_names = df2['Ticker Symbol'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set1 = set(sp500_names)\n",
    "set2 = set(fundamental_names)\n",
    "diff_names = set1.symmetric_difference(set2)\n",
    "diff_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SP500 with dropped names\n",
    "df4 = df3.drop(diff_names,axis = 0)\n",
    "df4 = df4.drop(['per_change'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.index = df2['Ticker Symbol']\n",
    "df2.drop(['Ticker Symbol'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(['Period Ending'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Information Technology only\n",
    "df5 = df4[df4['Sector'] == 'Information Technology']\n",
    "sec_only_name = df5.index.unique()\n",
    "len(sec_only_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping those that are not part of Information Technology Sector\n",
    "set3 = set(sec_only_name)\n",
    "set4 = set(df2.index.unique())\n",
    "diff_name_2 = set3.symmetric_difference(set4)\n",
    "len(diff_name_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df2\n",
    "df6 = df6.drop(diff_name_2,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size matches with sec_only_name\n",
    "len(df6.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Swapping name and date for index\n",
    "df5['name'] = df5.index\n",
    "df5.index = df5['date']\n",
    "df5 = df5.drop(['date'],axis = 1)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to calculate % PR for fundamental data of 2014, 2015\n",
    "#See if fundamental data affects PR of next years.\n",
    "for_2015 = df5['2015']\n",
    "for_2016 = df5['2016']\n",
    "PR_2015 = {}\n",
    "PR_2016 = {}\n",
    "\n",
    "for name in sec_only_name:\n",
    "    #Just making sure all names go through\n",
    "    print(name)\n",
    "    #For 2015\n",
    "    first_close = for_2015[for_2015['name'] == name].close[0]\n",
    "    last_close = for_2015[for_2015['name'] == name].close[-1]\n",
    "    PR_2015[name] = (last_close - first_close)/first_close\n",
    "    #For 2016\n",
    "    first_close = for_2016[for_2016['name'] == name].close[0]\n",
    "    last_close = for_2016[for_2016['name'] == name].close[-1]\n",
    "    PR_2016[name] = (last_close - first_close)/first_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the range of Year's for fundamental data\n",
    "dates = df6['For Year'].unique()\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df7 drops 2012, 2013, 2016\n",
    "df7 = df6\n",
    "df7 = df7.rename(index=str, columns={\"For Year\" : \"Year\"})\n",
    "df7 = df7[df7.Year != 2012]\n",
    "df7 = df7[df7.Year != 2013]\n",
    "df7 = df7[df7.Year != 2016]\n",
    "#df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PR2015 = pd.DataFrame(list(PR_2015.items()))\n",
    "df_PR2015 = df_PR2015.rename(index=str, columns={0 : \"Ticker Symbol\", 1 : \"Percent_Return\"})\n",
    "df_PR2015['Year'] = 2014.0\n",
    "df_PR2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PR2016 = pd.DataFrame(list(PR_2016.items()))\n",
    "df_PR2016 = df_PR2016.rename(index=str, columns={0 : \"Ticker Symbol\", 1 : \"Percent_Return\"})\n",
    "df_PR2016['Year'] = 2015.0\n",
    "df_PR2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([df_PR2015,df_PR2016], axis = 0)\n",
    "combined = combined.sort_values('Ticker Symbol')\n",
    "combined = combined.rename(index = str, columns = {\"Percent_Return\" : \"PR_NXT_YR\"})\n",
    "combined.index = combined['Ticker Symbol']\n",
    "#combined = combined.drop(['Ticker Symbol'], axis = 1)\n",
    "#combined\n",
    "#merge df7 into combined on key = Ticker Symbol and Year\n",
    "df8 = pd.merge(combined, df7, how = 'left', on = ['Ticker Symbol', 'Year'])\n",
    "#Drop the nulls\n",
    "df8 = df8.dropna()\n",
    "df8 = df8.reset_index(drop = True)\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there's still null\n",
    "#df8.isnull().sum() #NONE\n",
    "#need to drop some more columns that won't be nessecary anymore\n",
    "list(df8.columns)\n",
    "PR_NXT_YR = df8['PR_NXT_YR']\n",
    "df8 = df8.drop(['Ticker Symbol','Year', 'PR_NXT_YR'], axis = 1)\n",
    "#Yes I did all that then drop the 'PR_NXT_YR'? I did that to align all data correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pos_Or_Neg = []\n",
    "for num in PR_NXT_YR:\n",
    "    if num > 0:\n",
    "        Pos_Or_Neg.append(1)\n",
    "    elif num < 0:\n",
    "        Pos_Or_Neg.append(0)\n",
    "Pos_Or_Neg = pd.DataFrame(Pos_Or_Neg)\n",
    "df8['Outcome'] = Pos_Or_Neg\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df8.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DF8 is our final data we can use for our NN.\n",
    "DF8 consist of :\n",
    "- companies from the \"Information Technology\" sector\n",
    "- Price Return (in %) of all the companies for year 2015 and 2016.\n",
    "- Fundamental Data Represents fundamental data of all companies with respect to the extracted sector for end of 2014, and 2015\n",
    "\n",
    "# Now I will use Marin's implementation for NN to test whether we can predict a positive (1) or negative (0) return using these fundamental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_inputs(df, column):\n",
    "    '''\n",
    "    x value will be a 2d array consisting of all columns except \"column\"\n",
    "    y value will consist of # of different variables (outcomes), in our case it'll be 0 or 1.\n",
    "    '''\n",
    "    temp_df = df.drop(column, axis=1)\n",
    "    x = temp_df.values\n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    y = df[column].values.astype(np.float32)\n",
    "    y = y.reshape(-1, 1)\n",
    "    y = to_categorical(y)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = model_inputs(df8, 'Outcome')\n",
    "#Create test and train data. Random State = 42 because 42 is always the answer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "#normalizating data L2 is default.\n",
    "X_train = preprocessing.normalize(X_train)\n",
    "X_test = preprocessing.normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequential meaning nodes are connected in \n",
    "model = Sequential()\n",
    "\n",
    "#hidden layer 1, input dimensionality\n",
    "model.add(Dense(128, input_dim=X.shape[1], activation='relu'))\n",
    "\n",
    "#hidden layer 2\n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "#output layer\n",
    "model.add(Dense(y.shape[1], activation='sigmoid'))\n",
    "\n",
    "#compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['binary_accuracy'])\n",
    "\n",
    "#fit model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = model.predict(X_test)\n",
    "model_pred = np.argmax(model_pred, axis=1)\n",
    "y_test_model = np.argmax(y_test, axis=1)\n",
    "\n",
    "accuracy_score = metrics.accuracy_score(y_test_model, model_pred)\n",
    "print(accuracy_score)\n",
    "\n",
    "#Max = .6154\n",
    "#Mode = .5769\n",
    "#Min = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
