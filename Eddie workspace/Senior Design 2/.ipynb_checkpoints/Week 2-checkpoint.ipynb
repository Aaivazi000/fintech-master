{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMART GOAL #1\n",
    "#### ****Finish implementing a GAN for understanding and testing purposes.\n",
    "\n",
    "Source of tutorial : https://github.com/aadilh/blogs/tree/new/basic-gans/basic-gans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries for testing\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z(m, n):\n",
    "    return np.random.uniform(-1,1, size=[m, n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the tutorial, the user creates a random data of 10000 samples, 2D array. Here I will use data sample from SMART Goal #4 as input.\n",
    "#Generator. Z = data input, hsize = [16 nodes for layer1, 16 nodes for layer2], reuse = false (will not reuse layers)\n",
    "def generator(Z,hsize=[16, 16],reuse=False):\n",
    "    with tf.variable_scope(\"GAN/Generator\",reuse=reuse):\n",
    "        h1 = tf.layers.dense(Z,hsize[0],activation=tf.nn.leaky_relu)\n",
    "        h2 = tf.layers.dense(h1,hsize[1],activation=tf.nn.leaky_relu)\n",
    "        out = tf.layers.dense(h2,2)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator. X = our original dataset, other parameters are same as above.\n",
    "#This also haves an extra hidden layer, h3, for....\n",
    "def discriminator(X,hsize=[16, 16],reuse=False):\n",
    "    with tf.variable_scope(\"GAN/Discriminator\",reuse=reuse):\n",
    "        h1 = tf.layers.dense(X,hsize[0],activation=tf.nn.leaky_relu)\n",
    "        h2 = tf.layers.dense(h1,hsize[1],activation=tf.nn.leaky_relu)\n",
    "        h3 = tf.layers.dense(h2,2)\n",
    "        out = tf.layers.dense(h3,2)\n",
    "\n",
    "    return out, h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These placeholders are storage for us, in which tf.float32 is the type (in this case 32 bit float)\n",
    "#[None,2] represents : None = any number of rows, 2 = 2 columns.\n",
    "X = tf.placeholder(tf.float32,[None,2])\n",
    "Z = tf.placeholder(tf.float32,[None,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we set up the generator and discriminator\n",
    "#G_sample = generated data, r_logits/r_rep = real data, f_logits,g_rep = generated data\n",
    "G_sample = generator(Z)\n",
    "r_logits, r_rep = discriminator(X)\n",
    "f_logits, g_rep = discriminator(G_sample,reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The loss function for discriminator and generator, need to understand how this works and how it can be tweaked.\n",
    "disc_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=r_logits,labels=tf.ones_like(r_logits)) + tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits,labels=tf.zeros_like(f_logits)))\n",
    "gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=f_logits,labels=tf.ones_like(f_logits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The training for the discriminator and genereator, once again I will need to understand how this works and how it can be tweaked.\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,scope=\"GAN/Discriminator\")\n",
    "\n",
    "gen_step = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(gen_loss,var_list = gen_vars) # G Train step\n",
    "disc_step = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(disc_loss,var_list = disc_vars) # D Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get our result for our GAN\n",
    "sess = tf.Session()\n",
    "tf.global_variables_initializer().run(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the iteration for the GAN, again, I will need to understand how this works and tweaked.\n",
    "loss = []\n",
    "for i in range(1001):\n",
    "    X_batch = random_data(n=batch_size)\n",
    "    Z_batch = sample_Z(batch_size, 2)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        _, dloss = sess.run([disc_step, disc_loss], feed_dict={X: X_batch, Z: Z_batch})\n",
    "    rrep_dstep, grep_dstep = sess.run([r_rep, g_rep], feed_dict={X: X_batch, Z: Z_batch})\n",
    "\n",
    "    for _ in range(10):\n",
    "        _, gloss = sess.run([gen_step, gen_loss], feed_dict={Z: Z_batch})\n",
    "    rrep_gstep, grep_gstep = sess.run([r_rep, g_rep], feed_dict={X: X_batch, Z: Z_batch})\n",
    "    \n",
    "    loss.append([i,dloss,gloss])\n",
    "    #print (\"Iterations: %d\\t Discriminator loss: %.4f\\t Generator loss: %.4f\"%(i,dloss,gloss))\n",
    "    \n",
    "    #Because the scatter plot shows that the generatered data is everywhere (when use plt.plot, connected lines looks\n",
    "    #like some baby drew a picture) I will try to sort the data by \"days\" and try to plot again.\n",
    "    #Looks better when it's sorted, we can see a progression on how the generator is learning, but it is still very noisy\n",
    "    #Perhaps I can try a different NN model?\n",
    "    if i%100 == 0:\n",
    "        print (\"Iterations: %d\\t\"%(i))\n",
    "        plt.figure(figsize=(10,8))\n",
    "        g_plot = sess.run(G_sample, feed_dict={Z: Z_batch})\n",
    "        g_plot = g_plot[g_plot[:,1].argsort()]\n",
    "        plt.plot(X_batch[:,1], X_batch[:,0],color = \"red\")\n",
    "        plt.plot(g_plot[:,1],g_plot[:,0], color = \"blue\")\n",
    "        plt.xlabel(\"Days\")\n",
    "        plt.ylabel(\"USD ($)\")\n",
    "        plt.legend([\"Red = Real Data\", \"Blue = Generated Data\"])\n",
    "        plt.title(\"Real vs Generated Data\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph plot for Discriminator and Generator Loss\n",
    "#Lower Generator Loss is good, means it can fool the discriminator\n",
    "#Lower Discriminator Loss is good, means it can detect the fake data created by generator\n",
    "#When I have ran this, there were several graphs.\n",
    "#1) Generator sky rocketed and never came down. Discriminator stayed at 0\n",
    "#2) Both Generator and Discriminator bounced around at the beginning but converged in further iterations.\n",
    "loss = np.array(loss)\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.plot(loss[:,0],loss[:,1], color = 'red')\n",
    "plt.plot(loss[:,0],loss[:,2], color = 'blue')\n",
    "plt.legend([\"Red = Discriminator\", \"Blue = Generator\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot of how the generated graphs look like\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMART GOAL #2\n",
    "#### Research about RNN, this takes time series as input which will be very useful for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMART Goal #3\n",
    "#### ****Add more features into the random walk model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "np.random.seed(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number max returns 0 or higher\n",
    "def max(num):\n",
    "    if num > 0:\n",
    "        return num\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determineResult (num):\n",
    "    if num >= 1:\n",
    "        return 1\n",
    "    elif num < 1 and num > -1:\n",
    "        return 0\n",
    "    elif num <= -1:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_data(n):\n",
    "    #randomStock starts at $100\n",
    "    randomStock = [100]\n",
    "    data = []\n",
    "    result = 0\n",
    "\n",
    "    #There will be n # closing price total\n",
    "    #result states whether price has increased (1), decreased (-1), or same (0)\n",
    "    for i in range(n):\n",
    "        openPrice = randomStock[-1]\n",
    "        randomPercentWalk = 0\n",
    "\n",
    "        if result == 0:\n",
    "            randomPercentWalk = np.random.uniform(-.02,.02)\n",
    "\n",
    "        #Result increased before\n",
    "        elif result == 1:\n",
    "            #33% it'll increase again, determines % increase/decrease\n",
    "            probIncrease = np.random.randint(1,10)\n",
    "            if probIncrease % 3 == 0:\n",
    "                randomPercentWalk = np.random.uniform(0,.02)\n",
    "            else:\n",
    "                randomPercentWalk = np.random.uniform(-.02,.02)\n",
    "\n",
    "        #Result decreased before\n",
    "        elif result == -1:\n",
    "            #33% it'll increase again, determines % increase/decrease\n",
    "            probIncrease = np.random.randint(1,10)\n",
    "            if probIncrease % 3 == 0:\n",
    "                randomPercentWalk = np.random.uniform(-0.02,0)\n",
    "            else:\n",
    "                randomPercentWalk = np.random.uniform(-.02,.02)\n",
    "\n",
    "        #randNum determines if increase is abnormal or not\n",
    "        #if abnormal randX determines by how much times it'll multiply by\n",
    "        randNum = np.random.randint(1,11)\n",
    "        if randNum > 1 and randNum < 10:\n",
    "            closePrice = openPrice + openPrice * randomPercentWalk\n",
    "        else:\n",
    "            randX = np.random.randint(2,4) * randomPercentWalk\n",
    "            closePrice = openPrice + openPrice * randX\n",
    "\n",
    "        #Set result\n",
    "        result = determineResult(randomPercentWalk)\n",
    "\n",
    "        randomStock.append(max(closePrice))\n",
    "        data.append([randomStock[-1],i])\n",
    "\n",
    "    return np.array(data)\n",
    "    #Update 1 added conditional probability (result)\n",
    "    #Update 2 converted list into nparray for GAN testing\n",
    "randomStock = random_data(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.xlabel(\"Day\")\n",
    "plt.ylabel(\"USD ($)\")\n",
    "plt.plot(randomStock[:,1],randomStock[:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(randomStock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(randomStock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomStock = randomStock[randomStock[:,1].argsort()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomStock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
